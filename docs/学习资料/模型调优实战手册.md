# 模型调优实战手册：像调试家电一样优化AI模型

## 一、调优基础知识

### 1. 调优三要素
就像修理家电，模型调优也需要：
1. 诊断工具（评估指标）
2. 问题定位（性能瓶颈）
3. 解决方案（优化策略）

### 2. 常见问题与解决方案
```python
# 问题诊断工具箱
class ModelDiagnostics:
    def __init__(self, model, train_loader, val_loader):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.history = {'train_loss': [], 'val_loss': []}
    
    def check_gradients(self):
        """检查梯度状况"""
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                print(f"{name}:")
                print(f"梯度范数: {param.grad.norm().item()}")
                print(f"参数范数: {param.data.norm().item()}")
    
    def plot_loss_curves(self):
        """绘制损失曲线"""
        plt.figure(figsize=(10, 5))
        plt.plot(self.history['train_loss'], label='训练损失')
        plt.plot(self.history['val_loss'], label='验证损失')
        plt.title('损失曲线')
        plt.legend()
        plt.show()
```

## 二、数据预处理优化

### 1. 数据清洗
就像洗衣服前先分类：
```python
def clean_data(df):
    # 1. 处理缺失值
    df.fillna(df.mean(), inplace=True)
    
    # 2. 删除异常值
    Q1 = df.quantile(0.25)
    Q3 = df.quantile(0.75)
    IQR = Q3 - Q1
    df = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]
    
    # 3. 特征标准化
    scaler = StandardScaler()
    df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)
    
    return df_scaled
```

### 2. 数据增强
就像给照片加滤镜：
```python
# 图像数据增强
transforms = A.Compose([
    A.RandomRotate90(),
    A.Flip(),
    A.Transpose(),
    A.OneOf([
        A.IAAAdditiveGaussianNoise(),
        A.GaussNoise(),
    ], p=0.2),
    A.OneOf([
        A.MotionBlur(p=0.2),
        A.MedianBlur(blur_limit=3, p=0.1),
        A.Blur(blur_limit=3, p=0.1),
    ], p=0.2),
    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),
])
```

## 三、模型架构优化

### 1. 网络结构设计
就像设计房屋布局：
```python
class ImprovedModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super().__init__()
        # 1. 使用残差连接
        self.residual = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, input_size)
        )
        
        # 2. 添加注意力机制
        self.attention = nn.MultiheadAttention(input_size, num_heads=8)
        
        # 3. 分类头
        self.classifier = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(hidden_size, num_classes)
        )
    
    def forward(self, x):
        # 残差连接
        identity = x
        out = self.residual(x)
        out = out + identity
        
        # 注意力机制
        out, _ = self.attention(out, out, out)
        
        # 分类
        out = self.classifier(out)
        return out
```

### 2. 损失函数设计
就像设定目标：
```python
class CombinedLoss(nn.Module):
    def __init__(self, alpha=0.5):
        super().__init__()
        self.alpha = alpha
        self.ce = nn.CrossEntropyLoss()
        self.mse = nn.MSELoss()
    
    def forward(self, pred, target, aux_pred=None, aux_target=None):
        # 主任务损失
        main_loss = self.ce(pred, target)
        
        # 辅助任务损失（如果有）
        if aux_pred is not None and aux_target is not None:
            aux_loss = self.mse(aux_pred, aux_target)
            return main_loss + self.alpha * aux_loss
        
        return main_loss
```

## 四、训练过程优化

### 1. 学习率调度
就像调节空调温度：
```python
def get_lr_scheduler(optimizer):
    """获取学习率调度器"""
    return {
        'cosine': torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=100
        ),
        'plateau': torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', factor=0.1, patience=10
        ),
        'one_cycle': torch.optim.lr_scheduler.OneCycleLR(
            optimizer, max_lr=0.01, epochs=100, steps_per_epoch=len(train_loader)
        )
    }
```

### 2. 训练策略
就像制定健身计划：
```python
class AdvancedTrainer:
    def __init__(self, model, optimizer, scheduler, device):
        self.model = model
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.device = device
        
    def train_one_epoch(self, train_loader, criterion):
        self.model.train()
        total_loss = 0
        
        # 使用进度条
        with tqdm(train_loader, desc='Training') as pbar:
            for batch_idx, (data, target) in enumerate(pbar):
                data, target = data.to(self.device), target.to(self.device)
                
                # 1. 清零梯度
                self.optimizer.zero_grad()
                
                # 2. 前向传播
                output = self.model(data)
                loss = criterion(output, target)
                
                # 3. 反向传播
                loss.backward()
                
                # 4. 梯度裁剪
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                # 5. 参数更新
                self.optimizer.step()
                
                # 6. 更新进度条
                total_loss += loss.item()
                pbar.set_postfix({'loss': total_loss / (batch_idx + 1)})
        
        return total_loss / len(train_loader)
```

## 五、模型评估与调试

### 1. 性能评估
就像体检报告：
```python
class ModelEvaluator:
    def __init__(self, model, device):
        self.model = model
        self.device = device
        
    def evaluate(self, test_loader):
        self.model.eval()
        predictions = []
        targets = []
        
        with torch.no_grad():
            for data, target in test_loader:
                data = data.to(self.device)
                output = self.model(data)
                predictions.extend(output.argmax(dim=1).cpu().numpy())
                targets.extend(target.numpy())
        
        # 计算各种指标
        return {
            'accuracy': accuracy_score(targets, predictions),
            'precision': precision_score(targets, predictions, average='weighted'),
            'recall': recall_score(targets, predictions, average='weighted'),
            'f1': f1_score(targets, predictions, average='weighted')
        }
```

### 2. 可视化分析
就像使用显微镜：
```python
class ModelVisualizer:
    def __init__(self, model):
        self.model = model
    
    def plot_feature_maps(self, input_tensor):
        """可视化特征图"""
        activation = {}
        
        def get_activation(name):
            def hook(model, input, output):
                activation[name] = output.detach()
            return hook
        
        # 注册钩子
        for name, layer in self.model.named_modules():
            if isinstance(layer, nn.Conv2d):
                layer.register_forward_hook(get_activation(name))
        
        # 前向传播
        _ = self.model(input_tensor)
        
        # 绘制特征图
        for name, feat in activation.items():
            plt.figure(figsize=(20, 10))
            for i in range(min(feat.shape[1], 8)):
                plt.subplot(2, 4, i + 1)
                plt.imshow(feat[0][i].cpu())
                plt.title(f'{name}_channel_{i}')
            plt.show()
```

## 六、部署优化

### 1. 模型压缩
就像压缩行李：
```python
def compress_model(model, input_shape):
    """模型压缩流程"""
    # 1. 知识蒸馏
    teacher = model
    student = SmallerModel()
    distiller = Distiller(teacher, student)
    distiller.train()
    
    # 2. 剪枝
    pruner = torch.nn.utils.prune
    for name, module in student.named_modules():
        if isinstance(module, nn.Conv2d):
            pruner.l1_unstructured(module, name='weight', amount=0.3)
    
    # 3. 量化
    quantized_model = torch.quantization.quantize_dynamic(
        student, {nn.Linear}, dtype=torch.qint8
    )
    
    return quantized_model
```

### 2. 推理加速
就像给汽车换高效燃料：
```python
def optimize_inference(model, input_shape):
    """推理优化流程"""
    # 1. 导出ONNX
    torch.onnx.export(model, torch.randn(input_shape), 'model.onnx')
    
    # 2. TensorRT优化
    import tensorrt as trt
    logger = trt.Logger(trt.Logger.WARNING)
    builder = trt.Builder(logger)
    network = builder.create_network()
    parser = trt.OnnxParser(network, logger)
    
    # 3. 构建优化引擎
    config = builder.create_builder_config()
    config.max_workspace_size = 1 << 30
    engine = builder.build_engine(network, config)
    
    return engine
```

## 七、调优最佳实践

### 1. 调优流程
1. 建立基准模型
2. 问题诊断
3. 制定优化策略
4. 实施优化
5. 评估效果
6. 迭代改进

### 2. 调优技巧
- 从简单模型开始
- 一次只改一个参数
- 保持详细记录
- 定期备份模型
- 使用版本控制

## 八、常见陷阱与解决方案

### 1. 过度优化
- 症状：在训练集上表现极好，测试集表现差
- 解决：增加正则化，使用交叉验证

### 2. 资源浪费
- 症状：GPU利用率低，训练速度慢
- 解决：优化批量大小，使用数据并行

### 3. 优化方向错误
- 症状：优化后性能反而下降
- 解决：建立明确的评估指标，做好实验对照

## 九、进阶优化方向

### 1. 自动化调优
- 使用AutoML
- 超参数自动搜索
- 架构自动设计

### 2. 分布式优化
- 数据并行训练
- 模型并行训练
- 混合精度训练

## 十、调优工具箱

### 1. 监控工具
- TensorBoard
- Weights & Biases
- PyTorch Profiler

### 2. 调试工具
- pdb/ipdb
- torch.autograd.detect_anomaly()
- torch.autograd.profiler 
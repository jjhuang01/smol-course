# 模型评估与概率模型详解

## 一、模型评估

### 1. 准确率、精确率、召回率

#### 生活场景类比：垃圾邮件过滤器
想象你是一个邮件分拣员：
- 准确率：你正确分类的邮件占总邮件的比例
  ```python
  准确率 = (正确识别的垃圾邮件 + 正确识别的正常邮件) / 所有邮件
  ```

- 精确率：你标记为垃圾的邮件中，真正是垃圾的比例
  ```python
  精确率 = 正确识别的垃圾邮件 / 所有被标记为垃圾的邮件
  ```

- 召回率：真正的垃圾邮件中，被你找出来的比例
  ```python
  召回率 = 正确识别的垃圾邮件 / 所有实际的垃圾邮件
  ```

#### 实践代码
```python
from sklearn.metrics import accuracy_score, precision_score, recall_score

# 示例：垃圾邮件分类结果
y_true = [1, 0, 1, 1, 0, 1]  # 1表示垃圾邮件，0表示正常邮件
y_pred = [1, 0, 1, 0, 0, 1]  # 模型预测结果

# 计算各项指标
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
```

### 2. ROC曲线和AUC

#### 生活场景类比：疾病筛查
想象你是一个医生，需要通过体检结果判断病人是否患病：
- ROC曲线：就像是不同诊断标准下的效果图
  - 横轴：误诊率（把健康人误诊为病人）
  - 纵轴：正确诊断率（正确找出病人）

- AUC：曲线下面积，代表整体诊断能力
  - 1.0 是完美诊断
  - 0.5 相当于随机猜测

#### 实践代码
```python
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# 计算ROC曲线
fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)
roc_auc = auc(fpr, tpr)

# 绘制ROC曲线
plt.figure()
plt.plot(fpr, tpr, label=f'ROC曲线 (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('假阳性率')
plt.ylabel('真阳性率')
plt.title('ROC曲线示例')
plt.legend()
plt.show()
```

### 3. 交叉验证

#### 生活场景类比：教师备课
想象你是一个教师，要评估一个教学方法的效果：
- 不能只在一个班级试验
- 需要在多个不同班级测试
- 最后取平均效果

```python
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

# 5折交叉验证示例
kf = KFold(n_splits=5, shuffle=True)
scores = cross_val_score(model, X, y, cv=kf)
print(f"平均分数: {scores.mean():.2f} (+/- {scores.std() * 2:.2f})")
```

### 4. 过拟合与欠拟合

#### 生活场景类比：背书vs理解
- 过拟合：就像死记硬背考点
  - 考试内容变化就不会做
  - 模型过分记住训练数据的细节

- 欠拟合：就像完全没听课
  - 基本概念都没掌握
  - 模型太简单，无法学习到有用特征

## 二、概率模型

### 1. 最大似然估计

#### 生活场景类比：侦探破案
想象你是一个侦探：
- 收集各种线索（数据）
- 找出最可能的犯罪情节（参数）
- 选择最能解释所有线索的方案

```python
# 简单的最大似然估计示例
import numpy as np
from scipy.stats import norm

# 假设数据服从正态分布，估计均值和方差
data = np.random.normal(loc=5, scale=2, size=1000)
mu_mle = np.mean(data)  # 均值的最大似然估计
sigma_mle = np.std(data)  # 标准差的最大似然估计
```

### 2. 朴素贝叶斯

#### 生活场景类比：图书分类
想象你是图书馆管理员：
- 根据书名中的关键词判断图书类别
- 假设每个词都独立影响分类
- 根据以往经验计算概率

```python
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer

# 文本分类示例
texts = ["机器学习实战", "深度学习入门", "历史小说选集"]
labels = ["技术", "技术", "文学"]

# 特征提取
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(texts)

# 训练模型
model = MultinomialNB()
model.fit(X, labels)
```

### 3. 逻辑回归

#### 生活场景类比：预测下雨
想象你要预测明天是否下雨：
- 收集各种天气指标
- 计算下雨的概率
- 设定阈值做出判断

```python
from sklearn.linear_model import LogisticRegression

# 天气预测示例
# features: [温度, 湿度, 气压]
X = [[25, 80, 1013], [30, 60, 1015], [20, 90, 1008]]
y = [1, 0, 1]  # 1表示下雨，0表示晴天

model = LogisticRegression()
model.fit(X, y)
```

### 4. 概率神经网络

#### 生活场景类比：专家团队
想象一个医疗专家团队：
- 每个专家关注不同症状（神经元）
- 专家之间互相交流（网络连接）
- 综合多个意见做出诊断（概率输出）

```python
import torch
import torch.nn as nn

# 简单的概率神经网络示例
class ProbabilisticNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(10, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 2),
            nn.Softmax(dim=1)
        )
    
    def forward(self, x):
        return self.network(x)
```

## 三、实践建议

### 1. 模型评估
- 始终使用多个评估指标
- 根据实际问题选择合适的指标
- 注意数据集的平衡性
- 使用交叉验证增加可靠性

### 2. 概率模型选择
- 数据量小时考虑朴素贝叶斯
- 二分类问题可以用逻辑回归
- 复杂问题使用神经网络
- 注意模型的可解释性需求 